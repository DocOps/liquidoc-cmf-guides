= LiquiDoc
// tag::overview[]
LiquiDoc enables true single-sourcing of technical content and data.
It is especially suited for documentation projects with various required output formats, but it is intended for any project with complex, versioned input data for use in docs, user interfaces, and even back-end code.
The highly configurable command-line utility engages template engines to parse complex data into rich text output, from *blogs* to *books* to *knowledge bases* to *slide presentations*.

Sources can be flat files in formats such as *XML* (eXtensible Markup Language), *JSON* (JavaScript Object Notation), *CSV* (comma-separated values), and our preferred human-editable format: *YAML* (acronym link:https://en.wikipedia.org/wiki/YAML#History_and_name[in dispute]).
LiquiDoc also accepts *regular expressions* to parse unconventionally formatted files.

LiquiDoc relies heavily on the Asciidoctor rendering engine, which produces HTML, PDF, and soon several other rich-text output formats.

Output can (or will) be pretty much any flat file, including semi-structured data like JSON and XML, as well as rich text/multimedia formats like HTML, PDF, slide decks, and more.
// end::overview[]
// tag::rocana-note[]
[NOTE]
While the first two releases of LiquiDoc were released under the MIT license by my former employer, I do not believe the https://github.com/scalingdata/liquidoc-gem[originating repo] will be maintained.
Therefore, as of version 0.3.0, I maintain this fork under the MIT license.
More below under <<Contributing>> and <<License>>.

// end::rocana-note[]

== Purpose
// tag::purpose[]
LiquiDoc is a build tool for documentation projects or for the documentation component of a larger project.
Unlike tools that are mere converters, LiquiDoc can be easily configured to perform multiple consecutive routines for generating content from multiple data source files, each output in various formats based on distinct templates.
It can be integrated into build- and package-management systems.

The tool currently provides for very basic configuration of build jobs.
From any given data file, multiple template-driven parsing operations can be performed to produce totally different output formats from the same dataset.

=== Single-sourcing Docs _and_ Code

In order to achieve true single sourcing, a data source file in the simplest, most manageable format applicable to the job and preferred by the team, can serve as the canonical authority.
But rather than using this file as a mere _reference_ like most docs, every stakeholder on the team can draw from it programmatically.
Feature teams who need structured data in different formats can read the semi-structured source file from a common location and parse it using native libraries.
Alternatively, LiquiDoc can parse it into a generated source file during the product build procedure and save a copy in the target/build tree for the application build to pick up.

=== Coming Soon

Upcoming capabilities include a secondary publish function for generating link:http://asciidoctor.org/[Asciidoctor] output from data-driven AsciiDoc-formatted files to ePub and even HTML/JavaScript slide presentations, as well as integrated AsciiDoc- or Markup-based Jekyll static website generation.

See this link:https://github.com/briandominick/liquidoc-gem/issues?q=label%3Aenhancement[project's GitHub issues] for upcoming features, and feel free to add your own requests.
// end::purpose[]

// tag::installation[]
== Installation

[NOTE]
Your system must be running Ruby 2.3 or later.
Linux and MacOS users should be okay.
See https://rubyinstaller.org/downloads[rubyinstaller.org] if you're on Windows.

. Create a file called `Gemfile` in your project's root directory.

. Populate the file with LiquiDoc dependencies.
+
.A LiquiDoc project Gemfile
[source,ruby]
----
source 'https://rubygems.org'

gem 'json'
gem 'liquid'
gem 'asciidoctor'
gem 'asciidoctor-pdf'
gem 'logger'
gem 'crack'
gem 'liquidoc'
----
+
[TIP]
This file is included in the link:https://github.com/briandominick/liquidoc-boilerplate[LiquiDoc boilerplate files].

. Open a terminal (command prompt).
+
If you don't have a preferred terminal application, use your OS's magic search and look for `terminal`.

. Navigate to your project root directory.
+
.Example
----
cd Documents/workspace/my_project
----

. Run `bundle install` to prepare dependencies.
+
If you do not have Bundler installed, Ruby will tell you.
Enter `gem install bundler`, let Bundler install, _then repeat this step_.

Cool!
LiquiDoc should now be ready to run with Bundler support, which is the strongly recommended approach.
// tag::installation[]

== Usage
// tag::usage[]
// tag::usage-intro[]
LiquiDoc provides a Ruby command-line tool for processing source files into new text files based on templates you define.
These definitions can be command-line options, or they can be instructed by preset configurations you define in separate configuration files.

[TIP]
.Quickstart
If you want to try the tool out with dummy data and templates, clone link:https://github.com/briandominick/liquidoc-boilerplate[this boilerplate repo] and run the suggested commands.

Give LiquiDoc (1) any proper YAML, JSON, XML, or CSV (with header row) data file and (2) a template mapping any of the data to token variables with Liquid markup -- LiquiDoc returns STDOUT feedback or writes a new file (or multiple files) based on that template.

.Example -- Generate sample output from files passed as CLI arguments
----
bundle exec liquidoc -d _data/data-sample.yml -t _templates/liquid/sample.asciidoc -o _output/sample.adoc
----

[TIP]
Add `--verbose` to see the steps LiquiDoc is taking.

// end::usage-intro[]

=== Configuration
// tag::configuration[]
The best way to use LiquiDoc is with a configuration file.
This not only makes the command line much easier to manage (requiring just a configuration file path argument), it also adds the ability to perform more complex builds.

Here is the basic structure of a valid config file:

[source,yaml]
.Example config file for recognized format parsing
----
- action: parse # <1>
  data: source_data_file.json # <2>
  builds: # <3>
    - template: liquid_template.html # <4>
      output: _output/output_file.html # <5>
    - template: liquid_template.markdown # <4>
      output: _output/output_file.md # <5>
----

<1> The top-level `-` denotes a new, consecutively executed “step” in the build.
The *action* parameter determines what type of action this step will perform.
The options are `parse`, `migrate`, `render`, and `deploy`.

<2> If the *data* setting's value is a string, it must be the filename of a format automatically recognized by LiquiDoc: `.yml`, `.json`, `.xml`, or `.csv`.
Otherwise, *data* must contain child settings for *file* and *type*.

<3> The *builds* section contains a list of procedures to perform on the data.
It can include as many subroutines as you wish to perform.
This one instructs two builds.

<4> The *template* setting should be a liquid-formatted file (see <<templating>> below).

<5> The *output* setting is a path and filename where you wish the output to be saved.
Can also be `stdout`.

.Advanced Data Ingest
****
[source,yaml]
.Example config file for unrecognized format parsing
----
- action: parse
  data: # <1>
    file: source_data_file.json # <2>
    type: regex # <3>
    pattern: (?<kee>[A-Z0-9_]+)\s(?<valu>.*)\n # <4>
  builds:
    - template: liquid_template.html
      output: _output/output_file.html
    - template: liquid_template.markdown
      output: _output/output_file.md
----

<1> In this format, the *data* setting contains several other settings.

<2> The *file* setting accepts _any_ text file, no matter the file extension or data formatting within the file.
This field is required.

<3> The *type* field can be set to `regex` if you will be using a regular expression pattern to extract data from lines in the file.
It can also be set to `yml`, `json`, `xml`, or `csv` if your file is in one of these formats but uses a nonstandard extension.

<4> If your type is `regex`, you must supply a regular expression pattern.
This pattern will be applied to each line of the file, scanning for matches to turn into key-value pairs.
Your pattern must contain at least one group, denoted with unescaped `(` and `)` markers designating a “named group”, denoted with `?<string>`, where `string` is the name for the variable to assign to any content matching the pattern contained in the rest of the group (everything else between the unescaped parentheses.).
****

When you have established a configuration file, you can call it with the argument `-c`/`--config` on the command line.

.Example -- Generate sample output from files established in a configuration
----
bundle exec liquidoc -c _configs/cfg-sample.yml --stdout
----

[TIP]
Repeat without the `--stdout` flag and you'll find the generated files in `_output/`, as defined in the configuration.

// tag::configuration[]

=== Parse Operations

The primary type of action performed by LiquiDoc during a build step is parsing semi-structured data into any flat format desired.

==== Data Sources

Valid data sources come in a few different types.
There are the built-in data types (YAML, JSON, XML, CSV) vs free-form type (files processed using regular expressions, designated by the `regex` data type).
There is also a divide between simple one-record-per-line data types (CSV and regex), which produce one set of parameters for every line in the source file, versus nested data types that can reflect far more complex structures.

===== Native Nested Data (YAML, JSON, XML)

The native nested formats are actually the most straightforward.
So long as your filename has a conventional extension, you can just pass a file path for this setting.
That is, if your file ends in `.yml`, `.json`, or `.xml`, and your data is properly formatted, LiquiDoc will parse it appropriately.

For standard-format files that have non-standard file extensions (for example, `.js` rather than `.json` for a JSON file), you must declare a type explicitly.

[source,yaml]
.Example config -- Instructing correct type for mislabeled JSON file
----
- action: parse
  data:
    file: _data/source_data_file.js
    type: json
  builds:
    - template: _templates/liquid_template.html
      output: _output/output_file.html
----

Once LiquiDoc knows the right file type, it will parse the file into a Ruby hash data structure for further processing.

===== CSV Data

Data ingested from CSV files will use the first row as key names for columnar data in the subsequent rows, as shown below.

.Example -- sample.csv showing header/key and value rows
[source,csv]
----
name,description,default,required
enabled,Whether project is active,,true
timeout,The duration of a session (in seconds),300,false
----

The above source data, parsed as a CSV file, will yield an _array_.
Each array item represents a row from the CSV file (except the first row).
Each array item contains a _structure_, or what Ruby calls a _hash_.
As represented in the CSV example above, if the structure contains more than one key-value pair (more than one “column” in the source), all such pairs will be siblings, not nested or hierarchical.

.Example -- array derived from sample.csv, with values depicted
[source,ruby]
----
data[0].name #=> enabled
data[0].description #=> Whether project is active
data[0].default #=> nil
data[0].required #=> true
data[1].name #=> timeout
data[1].description #=> The duration of a session (in seconds)
data[1].default #=> 300
data[1].required #=> false
----

===== Free-form Data

Free-form data can only be parsed using regex patterns -- otherwise LiquiDoc has no idea what to consider data and what to consider noise.

Any file organized with one record per line may be consumed and parsed by LiquiDoc, provided you tell the parser which variables to extract from where.
The parser will read each line individually, applying your regex pattern to extract data using named groups.

[TIP]
.Learn regular expressions
If you're already familiar enough with regex, this note is not for you.
If you deal with docs but are not a regex user, become one.
I promise you will deem the initial hurdles worth surmounting.

.Example -- sample.free free-form data source file
----
A_B A thing that *SnASFHE&"\|+1Dsaghf true
G_H Some text for &hdf 1t`F false
----

[source,yaml]
.Example config -- Instructing correct type for mislabeled JSON file
----
- action: parse
  data:
    file: _data/sample.free
    type: regex
    pattern: ^(?<code>[A-Z_]+)\s(?<description>.*)\s(?<required>true|false)\n
  builds:
    - template: _templates/liquid_template.html
      output: _output/output_file.html
----

Let's take a closer look at that regex pattern.

.Example -- regular expression with named groups for variable generation
[source,regex]
----
^(?<code>[A-Z_]+)\s(?<description>.*)\s(?<required>true|false)\n
----

We see the named groups *code*, *description*, and *required*.
This maps nicely to a new array.

.Example -- array derived from sample.free using above regex pattern
[source,ruby]
----
data[0].code #=> A_B
data[0].description #=> A thing that *SnASFHE&"\|+1Dsaghf
data[0].required #=> true
data[1].code #=> G_H
data[1].description #=> Some text for &hdf'" 1t`F
data[1].required #=> false
----

Free-form/regex parsing is obviously more complicated than the other data types.
Its use case is usually when you simply cannot control the form your source takes.

The regex type is also handy when the content of some fields would be burdensome to store in conventional semi-structured formats like those natively parsed by LiquiDoc.
This is the case for jumbled content containing characters that require escaping, so you can keep source like that from the example above in the simplest possible form.

==== Default Output Formats

LiquiDoc can directly convert any semi-structured data input format to either YAML or JSON output.
Simply provide no template, and make sure the output file has a proper extension (`.yml` or `.json`).

.Example config snippet for data-to-data conversion
[source,yaml]
----
- action: parse
  data: _data/testdata.xml
  output: _build/frontend/testdata.json
----

XML and CSV output will be added in a future release.

==== Templating

link:https://help.shopify.com/themes/liquid/basics[*Liquid*] is used for parsing complex variable data, typically for iterated output.
For instance, a data structure of glossary terms and definitions that needs to be looped over and pressed into a more publish-ready markup, such as Markdown, AsciiDoc, reStructuredText, LaTeX, or HTML.

Any valid Liquid-formatted template is accepted, in the form of a text file with any extension.
For data sourced in CSV format or extracted through regex source parsing, all data is passed to the Liquid template parser as an array called *data*, containing one or more rows to be iterated through.
Data sourced in YAML, XML, or JSON may be passed as complex structures with custom names determined in the file contents.

Looping through known data formats is fairly straightforward.
A _for_ loop iterates through your data, item by item.
Each item or row contains one or more key-value pairs.

[[rows_asciidoc]]
.Example -- rows.asciidoc Liquid template
[source,liquid]
----
{% for row in data %}{{ row.name }}::
{{ row.description }}
+
[horizontal.simple]
Required:: {% if row.required == "true" %}*Yes*{% else %}No{% endif %}
{% endfor %}
----

In <<rows_asciidoc>>, we're instructing Liquid to iterate through our data items, generating a data structure called `row` each time.
The double-curly-bracketed tags convey variables to evaluate.
This means `{{ row.name }}` is intended to express the value of the *name* parameter in the item presently being parsed.
The other curious marks such as `::` and `[horizontal.simple]` are AsciiDoc markup -- they are the formatting we are trying to introduce to give the content form and semantic relevance.

.Non-printing Markup
****
In Liquid and most templating systems, any row containing a non-printing “tag” will leave a blank line in the output after parsing.
For this reason, it is advised that you stack tags horizontally when you do not wish to generate a blank line, as with the first row above.
A non-printing tag such as `{% endfor %}` will generate a blank line that is inconvenient in the output.

This side effect of templating is unfortunate, as it discourages elegant, “accordian-style” code nesting, like you see in the HTML example below (<<parsed_html>>).
In the end, ugly Liquid templates can generate quite elegant markup output with exquisite precision.
****

The above would generate the following:

[[asciidoc_formatted_source]]
.Example -- AsciiDoc-formatted output
[source,asciidoc]
----
A_B::
A thing that *SnASFHE&"\|+1Dsaghf
+
[horizontal.simple]
Required::: *Yes*

G_H::
Some text for &hdf'" 1t`F
+
[horizontal.simple]
Required::: No
----

The generically styled AsciiDoc rich text reflects the distinctive structure with (very little) more elegance.

.AsciiDoc rich text (rendered)
====
A_B::
A thing that *SnASFHE&"\|+1Dsaghf
+
[horizontal.simple]
Required::: *Yes*

G_H::
Some text for &hdf'" 1t`F
+
[horizontal.simple]
Required::: No
====

The implied structures are far more evident when displayed as HTML derived from Asciidoctor parsing of the LiquiDoc-generated AsciiDoc source (from <<asciidoc_formatted_source>>).

[[parsed_html]]
.AsciiDoc parsed into HTML
[source,html]
----
<div class="dlist data-line-1">
  <dl>
    <dt class="hdlist1">A_B</dt>
    <dd>
      <p>A thing that *SnASFHE&amp;"\|+1Dsaghf</p>
      <div class="hdlist data-line-5 simple">
        <table>
          <tr>
            <td class="hdlist1">
              Required
            </td>
            <td class="hdlist2">
              <p><strong>Yes</strong></p>
            </td>
          </tr>
        </table>
      </div>
    </dd>
    <dt class="hdlist1">G_H</dt>
    <dd>
      <p>Some text for &amp;hdf'" 1t`F</p>
      <div class="hdlist data-line-11 simple">
        <table>
          <tr>
            <td class="hdlist1">
              Required
            </td>
            <td class="hdlist2">
              <p>No</p>
            </td>
          </tr>
        </table>
      </div>
    </dd>
  </dl>
</div>
----

Remember, all this started out as that little old free-form text file.

.Example -- sample.free free-form data source file
----
A_B A thing that *SnASFHE&"\|+1Dsaghf true
G_H Some text for &hdf 1t`F false
----

==== Output

After this parsing, files are written in any of the given output formats, or else just written to system as STDOUT (when you add the `--stdout` flag to your command or set `output: stdout` in your config file).
Liquid templates can be used to produce any flat-file format imaginable.
Just format valid syntax with your source data and Liquid template, then save with the proper extension, and you're all set.
// end::usage[]

=== Migrate Operations

During the build process, different tools handle file assets variously, so your images and other embedded files are not always where they need to be relative to the current procedure.
Migrate actions copy resource files to a temporary/uncommitted directory during the build procedure so they can be readily accessed by subsequent steps.

In addition to designating `action: migrate`, migrate operations require just a few simple settings.

[source,yaml]
.Example config -- Instructing file copies with 'migrate' action
----
- action: migrate
  source: assets/images
  target: _build/img
  options:
    inclusive: false
- action: migrate
  source: index-map.adoc
  target: _build/index-map.adoc
----

The first action step above copies all the files and folders in `assets/images` and adds them to `_build/img`.
It will only recreate the contents of the source directory, not the directory path itself, because the *inclusive* option is set to `false` (though its default is `true`).
When both the source and target paths are directories and inclusive is `true`, the files are copied to `target/source/`.
When inclusive is `false`, they copy to `target/`.

Individual files must be listed in individual steps at this time, one per step, as in the second step.

=== Render Operations

Presently, all render actions convert AsciiDoc-formatted source files into rich-text documents, such as PDFs and HTML pages.
LiquiDoc uses Asciidoctor's Ruby engine and various other plugins to generate output in a few supported formats.

First let's look at a render action configuration step.

[source,yaml]
.Example config -- Instructing Asciidoctor conversions with 'render' action
----
- action: render
  source: book-index.adoc
  data: _config/asciidoctor.yml
  builds:
    - output: _build/publish/codewriting-book-draft.pdf
      theme: theme/pdf-theme.yml
    - output: _build/publish/codewriting-book-draft.html
      theme: theme/site.css
    - output: _build/publish/codewriting-book-draft.epub
----

Each render action requires an index, which is the primary AsciiDoc file to process labeled *source* in our configuration.
This file can contain all of your AsciiDoc content, if you wish.
Alternatively, it can be made up entirely of `include::` macros, creating an linear map of your document's contents, which may themselves be more AsciiDoc files, code examples, and so forth.

[[_fig_index_file]]
[source,asciidoc]
.Example AsciiDoc index file
----
= This File Can Contain Regular AsciiDoc Markup

\include::chapter-01.adoc[]

\include::code-sample.rb[tags="booksample"]

\include::code-sample.js[lines="22..33"]
----

After the title line, the first macro instruction in this example will embed the entire file `chapter-01.adoc`, parsing and rendering its AsciiDoc-formatted contents in the process.

The second instruction extracts part of the file `code-sample.rb` and embeds it here.
Inside `codesample.rb`, content is tagged with comment code to mark what we wish to extract.
In the case of a Ruby file, you would expect to find code like the following in the source.

[source,ruby]
.Example Ruby code snippet tagged for inclusion
----
# tag::booksample[]
def exampleblock
  puts "This is an example for my book."
end
# end::booksample[]
----

For AsciiDoc source code, you would use the `//` comment notation.

[source,asciidoc]
.Example AsciiDoc code snippet tagged for inclusion
----
// tag::booksample[]
purpose::
to demonstrate inclusion.
// end::booksample[]
----

The third instruction in our <<_fig_index_file>>, which was simply include::code-sample.js[lines="22..33"] -- this dangerous little bugger extracts a fixed span of code lines, as designated.

==== Static Site Render Operations

Static-site generators are critical tools to just about any docs-as-code infrastructure.
Starting with Jekyll but soon to add more (link:http://awestruct.org[Awestruct] and possibly link:https://sysgears.com/grain/[Grain] next), each generator added will maintain all of its capabilities and do most of the heavy lifting.

LiquiDoc's role is primarily to help your preferred SSG handle your source in ways consistent with any other rendering and file managing your docs codebase requires.
For example, the jekyll-asciidoc extension that enables Jekyll builds to parse AsciiDoc markup only honors attributes set in Jekyll config files.
Therefore, just before triggering the build, LiquiDoc writes a new config file from which Jekyll draws AsciiDoc attribute assignments.

Jekyll::
A Jekyll render operation calls `bundle exec jekyll build` from the command line pretty much the way you would do it manually.
You still need a Jekyll configuration file with the usual settings in it.
This is established in your build-config block

[source,yaml]
.Example Jekyll render action
----
- action: render
  data: globals.yml
  builds:
    - backend: jekyll
      properties:
        files:
          - _configs/jekyll-global.yml
          - _configs/jekyll-portal-1.yml
        arguments:
          destination: build/site/user-basic
      attributes:
        portal_term: Guide
----

The *backend* designation of `jekyll` is required, and at least one file under *properties* > *files* is strongly encouraged for proper Jekyll behavior.
LiquiDoc will write an additional YAML file containing all of the AsciiDoctor attributes will be appended to this list when the build command is run, thus capturing attributes offerd up in the action-level *data* file and the *arguments* block in the .

The *arguments* block is made up of key-value parameters that establish or override any Jekyll config settings.

[NOTE]
The action-level parameter *source* is left blank in this example.
This setting is _cannot_ be used to designate a Jekyll source path.
If the above action had a second build step, such as a single output doc, the source would have relevance as the index file for that document.

[[asciidoc-attributes]]
==== Setting AsciiDoc Attributes

For basic `render` actions, the *source* file and other `.adoc` files determine most of the rest of the content source files (if any) using AsciiDoc includes.
But Asciidoctor renderings can be configured and manipulated by _attribute_ settings at other stages.
Basically, we are trying to maximize our readiness to ingest document data and build properties from a wide range of sources.
This way inline substitutions can be made out of data living outside the source tree of any particular document, passed into the document build in the form of YAML data converted into -- you guessed it -- AsciiDoc _attributes_.

LiquiDoc provides several means for adding attributes to your documents, in addition to the ways you might be used to setting attributes (inside your docfiles and command line).
They are listed below _in the order of assignment/substitution_.
Therefore, an identical value defined explicitly in each subsequent space will overwrite any set in the previous stages.

The order of substitution is as follows.

. <<asciidoc-doc-inline,AsciiDoc document inline>>
. <<document data file,document-data-file>>
. <<per-build-properties-files,per-build properties files>>
. <<per-build-liquidoc-config,per-build in LiquiDoc config>>
. <<command-line-arguments,command-line arguments>>

After that, we'll demonstrate even <<more-data,more ways to ingest datasets>>.

[[asciidoc-doc-inline]]
AsciiDoc document inline::
The most common way to set variables is inside your AsciiDoc source files -- typically at the top of your `index.adoc` file or the equivalent.
Any parameters set there will cascade through your files for parsing.
This is a good place to establish defaults, but they can be overwritten by the other three means of setting AsciiDoc attributes.
+
[source,asciidoc]
.Example -- Setting AsciiDoc attributes inline
----
:some_var: My value
:imagesdir: ./img
----

[[document-data-file]]
Document data file::
A YAML-formatted data file containing a stack of key-value pairs can be passed to Asciidoctor.
+
[source,yaml]
.Example AsciiDoc attributes data file
----
imagesdir: assets/images
basedir: _build
my_custom_var: Some text, can include spaces and most punctuation
----
+
This file must be called out in your configuration using the top-level *data* setting.
+
[source,yaml]
.Example AsciiDoc data file setting for attributes ingest
----
- action: render
  source: my_index.adoc
  data: _data/asciidoctor.yml
  builds:
    - output: myfile.html
----
+
You may also pass *multiple files* and/or just a sub-block of a given file (a named variable with its own nested data).
See <<#more-data,below>>.

[[per-build-properties-files]]
Per-build properties files::
With document-wide attributes set, we begin overwriting them on a _per-build_ basis for different renderings of that same source document.
For starters, LiquiDoc can extract attributes from still more data files at this stage, like so:
+
.Example -- Attribute extraction from build-specific data files
[source,yaml]
----
  - output: _build/publish/manual-europe.pdf
    properties:
      files: _conf/jekyll.yml,_data/europe.yml
  - output: _build/publish/manual-china.pdf
    properties:
      files: _conf/jekyll.yml,_data/china.yml
----
+
The *properties* > *files* setting can take the form of a comma-delimited list or a YAML array, and it can filter to specific subdata (see <<#more-data,below>>).
These per-build properties files are meant to be document settings, so for static site renderings (e.g., Jekyll), these are meant to contain YAML files formatted for Jekyll configuration reads.

[[per-build-liquidoc-config]]
Per-build in LiquiDoc config::
So if your _document_ is a book, and your _builds_ are an HTML edition and a PDF edition, you can pass distinct settings to each.
+
[source,yaml]
.Example per-build attribute settings in config file
----
  - action: render
    source: my_book.adoc
    data: _data/asciidoctor.yml
    builds:
      - output: my_book.html
        attributes:
          edition: HTML
      - output: my_book.pdf
        attributes:
          edition: PDF
      - output: my_book_special.pdf
        attributes:
          edition: Special
----
+
Imagine this affecting content in the book file.
+
[source,asciidoc]
.Example book index with variable content
----
= My Awesome Book: {edition} Edition

\include::chapter-1.adoc[]

\include::chapter-2.adoc[]
\ifeval::[{edition} == "Special"]
\include::chapter-3.adoc[]
\endif::[]
----
+
The AsciiDoc code above that might be least familiar to you is conditional code, represented by the `ifeval::[]` and `endif::[]` markup.
Here we see how passing attributes at the _build iteration_ level gives us all kinds of cool powers.
Not only are we setting the subtitle with a variable; if we're building the special edition, we add a chapter the other two editions ignore.

[[command-line-arguments]]
Command-line arguments::
There is yet a way to override all of this, which is also handy for testing variables out without editing any files:
pass arguments via the `-a` command-line argument.
The `-a` option flag accepts an argument in the format of `key=value`, where `key` is the name of your attribute, and `value` is your optional assignment for that attribute.
You may pass as many attributes as you like this way, up to the capacity of your shell's command line, which is probably something.
+
[source,bash]
.Example -- Setting global build attributes on the CLI
----
bundle exec liquidoc -c _configs/my_book.yml -a edition='Very Special NSFW' -a testvar=working
----

[[more-data]]
==== More ways to Ingest Attributes Data

multiple attribute files::
You may also specify more than one attribute file by separating filenames with commas.
They will be processed in order.

specific subdata::
You may designate a specific block in your data file by designating it with a colon.
+
.Example -- Listing multiple data files & designating a nested block
[source,yaml]
----
  data:
    - asciidoc.yml
    - product.yml:settings.attributes
----
+
.Example -- Designating a data block -- alternate format
[source,yaml]
----
  properties:
    files: asciidoc.yml,product.yml:settings.attributes
----
+
Here we see `,` used as a delimiter between files and `:` as an indicator that a variable indicator follows.
In this case, the render action will load the `settings.attributes` block from the `product.yml` file.
+
.Example -- Designating data blocks within a properties files
[source,yaml]
----
  properties:
    files:
      - countries.yml:china
      - edition.yml:enterprise.premium
----

==== Render Build Settings Overview

Certain AsciiDoc/Asciidoctor settings are determinant enough that they can be set using parameters in the build config.
Establishing these as per-build settings in your config file will override anywhere else they are set, except on the command line.

[IMPORTANT]
These settings do not necessarily have 1:1 correspondence to AsciiDoc(tor) attributes.

output::
The filename for saving rendered content.
This build setting is required for render operations that generate a single file.
Static site generation renders, however, target a directory set in the SSG's config.

backend::
The backend determines the rendering context.
When building single-file output, the backend is typically determined from the *output* filename and/or the *doctype*.
Some renderers, such as Jekyll, require specific backend designations (`jekyll`).
Valid options are `html5`, `pdf`, `jekyll`, with more to come.

doctype::
Overrides *doctype* attribute.
Valid values are:

`book`:::
Generates a book-formatted document in PDF, HTML, or ePub.

`article`:::
Generates an article-formatted document in PDF, HTML, or ePub.

`manpage`:::
Generates Linux man page format.

`deck`:::
Generates an HTML/JavaScript slide deck. (Not yet implemented.)

`style`::
Points either to a YAML configuration for PDF styles or a CSS stylesheet for HTML rendering.

properties::
Designate a file or files for settings and additional explicit settings at the build level.
See <<per-build-properties-files>>.

=== Deploy Operations

It's not clear how deeply we will delve into deploy operations, since other build systems (such as rake) would seem far more suitable.
For testing purposes, however, spinning up a local webserver with the same stroke that you build a site is pretty rewarding and time saving.

For now, this functionality is limited to adding a `--deploy` flag to your `liquidoc` command.
This will attempt to serve files from the *destination* set for the associated Jekyll build.

[WARNING]
Deployment of Jekyll sites is both limited and untested under nonstandard conditions.

=== Config Settings Matrix

Here is a table of all the established configuration settings, as they pertain to each key LiquiDoc action.

// tag::options-table[]
[cols="3,1,1,1,1",options="header"]
|===
| Setting
| Parse
| Migrate
| Render
| Deploy

5+s| Main Per-step Settings

s| action
| Required
| Required
| Required
|

s| data
| Required
| N/A
| Optional
|

s| source
| N/A
| Required
| Required
|

s| target
| N/A
| Required
| N/A
|

s| options
| N/A
| Optional
| Optional
|

s| builds
| Required
| N/A
| Required
|

5+s| Per-Build Settings

s| output
| Required
| N/A
| Optional*
|

s| backend
| N/A
| N/A
| Optional
|

s| config
| N/A
| N/A
| Optional
|

s| template
| Optional
| N/A
| N/A
|

s| style
| N/A
| N/A
| Optional
|

s| attributes
| N/A
| N/A
| Optional
|

s| properties
| N/A
| N/A
| Optional
|
|===

pass:[*]The `output` setting is considered optional for render operations because static site generations target a directory set in the SSG's config file.
// end::options-table[]

== Meta
// tag::meta[]
I get that this is the least sexy tool anyone has ever built.
I truly do.

Except I kind of disagree.
To me, it's one of the most elegant ideas I've ever worked on, and I actually adore it.

Maybe it's due to my love of flat files.
The simplicity of _anything in / anything out_ for flat files is such a holy grail in my mind.
I am a huge fan of link:http://pandoc.org/[Pandoc], which has saved me countless hours of struggle.
I totally dig markup languages and dynamic template engines, both of which I've been using to build cool shit for almost 20 years.

You don't have to love it to use it, or even to contribute.
But if you get what I'm trying to do, give a holler.

The reason I'm developing LiquiDoc is to most flexibly handle common single-sourcing challenges posed by a divergence in tools.
I intend to experiment with other toolchains, datasource types, and template engines, but the point of this utility is to pull together great technologies to solve tough, recurring problems.
// end::meta[]

=== Contributing
// tag::contributing[]
Contributions are very welcome.

This repo is maintained by the former Technical Documentation Manager at Rocana (formerly ScalingData, now mostly acquired by Splunk), which is the original copyright holder of LiquiDoc.
I am teaching myself basic Ruby scripting just to code LiquiDoc and related tooling.
Therefore, *instructional pull requests are encouraged*.
I have no ego around the code itself.
I know this isn't the best, most consistent Ruby scripting out there, and I confess I'm more interested in what the tool _does_ than how it does it.
Help will be appreciated.

That said, because this utility is also made to go along with my book _Codewriting_, *I prefer not to overcomplicate the source code*, as I want relative beginners to be able to intuitively follow and maybe even modify it.
I guess by that I mean, I'm resisting over-abstracting the source -- I must be the beginner I have in mind.

I am very eager to collaborate, and I actually have extensive experience with collective authorship and product design, but I'm not a very social _programmer_.
If you want to contribute to this tool, please get in touch.
A *merge request* is a great way to reach out.
// end::contributing[]

=== Licensing
// tag::licensing[]
LiquiDoc link:https://github.com/scalingdata/liquidoc-gem[originated] under the copyright of Rocana, Inc, released under the MIT License.
*This fork* is maintained by Brian Dominick, the original author.
link:https://www.theregister.co.uk/2017/10/10/splunk_acquires_rival_rocana/[Rocana has been acquired by Splunk], but the author and driving maintainer of this tooling chose not to continue on with the rest of Rocana engineering, precisely in order to openly explore what tooling of this kind can do in various environments.

I am not sure if the copyright for the prime source transferred to Splunk, but it does not matter.
This fork repository will be actively maintained by the original author, and my old coworkers and their new employer can make make use of my upgrades like everyone else.

[NOTE]
The LiquiDoc gem at rubygems.org has been published out of this repo starting with version 0.2.0.

// tag::licensing[]

=== Consulting
// tag::consulting[]
LiquiDoc and _Codewriting_ author Brian Dominick is now available for contract work around implementation of advanced docs-as-code infrastructure.
I am eager to work with engineering and support teams at software companies.
I'm also seeking opportunities to innovate management of documentation and presentations at non-software organizations -- especially if you're working to make the world a better place!
Check out link:https://codewriting.org[codewriting.org] for more info.

// end::consulting[]
